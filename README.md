# ScholarSource

**Find high-quality study resources aligned with your textbook for Google NotebookLM**

ScholarSource is a web application that helps students discover curated educational resources that complement their course textbooks. By analyzing your book's structure and topics, ScholarSource finds open textbooks, course materials, and learning resources you can add to Google NotebookLM to create comprehensive study materials like flashcards and quizzes.

---

## ğŸ¯ Purpose

Students often struggle to find supplementary learning materials that align with their specific textbook. ScholarSource solves this by:

1. **Analyzing your book's structure** - Extracts table of contents, topics, and key concepts from book metadata, PDFs, or course pages
2. **Finding aligned resources** - Searches for 5-7 high-quality, legally accessible resources that follow similar structure to your textbook
3. **Validating quality** - Ensures resources are free, legal, NotebookLM-compatible, and from reputable sources
4. **Presenting actionable results** - Provides a student-friendly guide with direct links ready to import into NotebookLM

**Key Feature:** Prioritizes text-based resources (PDFs, web pages) that NotebookLM processes best, with YouTube videos as supplementary materials.

---

## âš¡ Quick Start

Get ScholarSource running locally in 5 minutes!

### Prerequisites
- Python >=3.10 <3.13 with virtual environment
- Node.js >=18 and npm
- Supabase project with jobs table created
- Environment variables configured (see [Installation](#-installation) for details)

### 1. Install Dependencies

**Backend:**
```bash
# From project root
pip install -e .
```

**Frontend:**
```bash
cd web
npm install
```

### 2. Start Services

Open two terminal windows:

**Terminal 1 - Backend:**
```bash
source .venv/bin/activate
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```
âœ… Backend running at: http://localhost:8000

**Terminal 2 - Frontend:**
```bash
cd web
npm run dev
```
âœ… Frontend running at: http://localhost:5173

### 3. Test It!

1. Open http://localhost:5173 in your browser
2. Fill in "Course Name" field (e.g., "Introduction to Algorithms")
3. Click "Find Resources"
4. Wait 1-5 minutes for AI agents to discover resources
5. Copy URLs and paste into NotebookLM!

### Verify It's Working

**Check Backend Health:**
```bash
curl http://localhost:8000/api/health
```

Should return:
```json
{
  "status": "healthy",
  "version": "0.1.0",
  "database": "connected"
}
```

**Check Frontend:**
Open http://localhost:5173 - you should see the course input form.

> **Need help?** See the [Troubleshooting](#-troubleshooting) section below for common issues.

---

## ğŸ—ï¸ Architecture

ScholarSource is a full-stack application with a modern, scalable architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                           â”‚
â”‚                                                                   â”‚
â”‚  React + Vite Frontend (Cloudflare Pages - Free)                â”‚
â”‚  - Course/Book input form (9 optional fields)                    â”‚
â”‚  - Real-time job status polling                                  â”‚
â”‚  - Results table with resource links                             â”‚
â”‚  - Export to NotebookLM functionality                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ HTTPS API Calls
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BACKEND API                                 â”‚
â”‚                                                                   â”‚
â”‚  FastAPI (Railway - $5/month)                                   â”‚
â”‚  - POST /api/submit - Create background jobs                    â”‚
â”‚  - GET /api/status/{job_id} - Poll job status                   â”‚
â”‚  - GET /api/results/{job_id} - Shareable results                â”‚
â”‚  - GET /api/health - Health check                               â”‚
â”‚                                                                   â”‚
â”‚  Background Job Processing:                                      â”‚
â”‚  - Async crew execution in threads (2-5 min runtime)            â”‚
â”‚  - Markdown parsing to structured JSON                           â”‚
â”‚  - No timeouts (critical for long-running AI tasks)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Database Operations
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATABASE                                    â”‚
â”‚                                                                   â”‚
â”‚  Supabase PostgreSQL (Free tier / $25/mo Pro)                   â”‚
â”‚  - Jobs table (UUID-based, persistent storage)                  â”‚
â”‚  - Job states: pending â†’ running â†’ completed/failed             â”‚
â”‚  - Persistent job results that survive server restarts          â”‚
â”‚  - JSONB fields for flexible data storage                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Crew Execution
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI AGENT SYSTEM                               â”‚
â”‚                                                                   â”‚
â”‚  CrewAI Multi-Agent Framework                                   â”‚
â”‚  - Book Structure Analyst (GPT-4o + FileReadTool)              â”‚
â”‚  - Resource Discovery Agent (GPT-4o-mini + SerperDevTool)       â”‚
â”‚  - Resource Validator (GPT-4o-mini + Web/YouTube tools)         â”‚
â”‚  - Output Formatter (GPT-4o)                                    â”‚
â”‚                                                                   â”‚
â”‚  External APIs:                                                  â”‚
â”‚  - OpenAI API (GPT-4o, GPT-4o-mini)                            â”‚
â”‚  - Serper API (web search)                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Technology Stack

### Frontend
- **React + Vite** - Modern, fast frontend framework
- **Deployment**: Cloudflare Pages (Free tier)
  - Unlimited bandwidth
  - Global CDN
  - Automatic HTTPS

### Backend
- **FastAPI** - Python web framework for REST API
- **Deployment**: Railway ($5/month)
  - **Why Railway?**
    1. âœ… **No request timeouts** - CrewAI jobs run 2-5 minutes without interruption
    2. âœ… **Always-on service** - No cold starts when students are waiting
    3. âœ… **WebSocket support** - Critical for streaming real-time progress updates
    4. âœ… **Simpler than alternatives** - Less complexity than Fly.io, better reliability than Render free tier
  - **Why NOT alternatives?**
    - Render free tier: 30-second timeout (dealbreaker for long AI jobs)
    - Render paid ($7): Works but cold starts hurt UX
    - Fly.io: Unnecessary complexity overhead
    - DigitalOcean: Works but Railway has better integration

### Database
- **Supabase PostgreSQL**
- **Deployment**: **Standalone Supabase** (not Railway's database add-on)
  - Free tier: 500MB database, 50,000 monthly active users
  - Pro tier: $25/month when scaling is needed
  - **Why standalone Supabase?**
    1. âœ… **Better pricing** - Free tier vs Railway's $10+/month database add-on
    2. âœ… **Superior tooling** - Dashboard, SQL Editor, real-time subscriptions
    3. âœ… **Auth ready** - Built-in authentication for future user accounts feature
    4. âœ… **Independent scaling** - Database and backend scale separately
    5. âœ… **Portable** - Easy to switch backend providers without data migration

### AI Agent System
- **CrewAI** - Multi-agent orchestration framework
- **OpenAI API** - GPT-4o and GPT-4o-mini models
- **Serper API** - Web search capabilities
- **CrewAI Tools**:
  - `FileReadTool` - Extract table of contents from PDF textbooks
  - `SerperDevTool` - Search for educational resources
  - `WebsiteSearchTool` - Validate web page quality
  - `YoutubeVideoSearchTool` - Validate YouTube video content

---

## ğŸ“¦ Installation

### Prerequisites
- Python >=3.10 <3.13
- Node.js >=18 (for frontend)
- [UV](https://docs.astral.sh/uv/) for Python dependency management

### Backend Setup

1. **Install UV** (if not already installed):
```bash
pip install uv
```

2. **Install Python dependencies**:
```bash
crewai install
```

3. **Update dependencies** (when adding/changing packages in `pyproject.toml`):
```bash
uv pip compile pyproject.toml -o requirements.txt
git add requirements.txt
git commit -m "Update dependencies"
```

4. **Set up environment variables** (`.env` file):
```bash
# OpenAI API
OPENAI_API_KEY=your_openai_api_key

# Serper API (web search)
SERPER_API_KEY=your_serper_api_key

# Supabase Database
SUPABASE_URL=https://your-project-id.supabase.co
SUPABASE_KEY=your_anon_or_service_role_key
```

5. **Create Supabase database table**:

Go to Supabase Dashboard â†’ SQL Editor and run:

```sql
CREATE TABLE jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    status TEXT NOT NULL CHECK (status IN ('pending', 'running', 'completed', 'failed')),
    inputs JSONB NOT NULL,
    results JSONB,
    raw_output TEXT,
    error TEXT,
    status_message TEXT,
    search_title TEXT,
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    completed_at TIMESTAMPTZ
);

CREATE INDEX idx_jobs_status ON jobs(status);
CREATE INDEX idx_jobs_created_at ON jobs(created_at DESC);

ALTER TABLE jobs ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Enable all access for jobs" ON jobs
    FOR ALL USING (true);
```

### Frontend Setup

1. **Navigate to web directory**:
```bash
cd web
```

2. **Install Node dependencies**:
```bash
npm install
```

3. **Create environment file** (`web/.env.local`):
```bash
VITE_API_URL=http://localhost:8000
```

---

## ğŸ® Running the Application

> **First time?** See the [Quick Start](#-quick-start) section above for a streamlined setup guide.

### Development Mode

**Terminal 1 - Start Backend API:**
```bash
# From project root
source .venv/bin/activate
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Start Frontend Dev Server:**
```bash
# From web/ directory
cd web
npm run dev
```

**Access the app:** http://localhost:5173

**Development Workflow:**
1. Both servers auto-reload on file changes
2. Make changes to backend code â†’ backend auto-reloads
3. Make changes to frontend code â†’ frontend hot-reloads in browser
4. Test changes immediately without manual restarts

### CLI Testing (Without Web UI)

Test the CrewAI agents directly from command line:

```bash
# Example 1: By book title and author
python src/scholar_source/main.py \
  --book-title "Introduction to Algorithms" \
  --book-author "Cormen, Leiserson, Rivest, Stein"

# Example 2: By ISBN
python src/scholar_source/main.py --isbn "978-0262046305"

# Example 3: By PDF file
python src/scholar_source/main.py --book-pdf-path "/path/to/textbook.pdf"

# Example 4: By book URL
python src/scholar_source/main.py \
  --book-url "https://mitpress.mit.edu/9780262046305/introduction-to-algorithms/"

# Example 5: By course information (shorthand)
python src/scholar_source/main.py \
  -u "Northwestern University" \
  -c "GEN_ENG 205-2"

# Test with verbose output
python test_crew.py
```

**Available CLI Arguments:**
- `-u, --university-name` - University name (e.g., "MIT")
- `-c, --course-name` - Course name (e.g., "Introduction to Algorithms")
- `-url, --course-url` - Course webpage URL
- `-b, --textbook` - Textbook information (legacy)
- `-t, --topics-list` - Comma-separated topics
- `--book-title` - Book title
- `--book-author` - Book author(s)
- `--isbn` - ISBN of the book
- `--book-pdf-path` - Local path to PDF
- `--book-url` - Online link to book

**Note:** At least one argument must be provided.

---

## ğŸ”§ Configuration

### Agent Configuration

Edit [src/scholar_source/config/agents.yaml](src/scholar_source/config/agents.yaml) to customize:
- Agent roles and goals
- LLM models (GPT-4o, GPT-4o-mini)
- Agent backstories and expertise

### Task Configuration

Edit [src/scholar_source/config/tasks.yaml](src/scholar_source/config/tasks.yaml) to customize:
- Task descriptions and priorities
- Expected outputs
- Resource quality criteria

### Crew Logic

Edit [src/scholar_source/crew.py](src/scholar_source/crew.py) to:
- Add/remove agents
- Configure agent tools
- Change task execution order (sequential/hierarchical)

---

## ğŸ“Š How It Works

### 1. User Submits Book Information
Students provide one or more of:
- Book metadata (title, author, ISBN)
- PDF file of the textbook
- Book URL (publisher website, Amazon, etc.)
- Course information (university, course name, URL)

### 2. Background Job Created
- FastAPI creates a job in Supabase database
- Job ID returned to frontend
- CrewAI execution starts in background thread

### 3. AI Agent Workflow (2-5 minutes)

**Agent 1: Book Structure Analyst (GPT-4o)**
- Reads PDF to extract table of contents (if provided)
- Analyzes book metadata to infer topics
- Identifies course level and discipline area
- Outputs: course_title, topics list, key_concepts, course_level

**Agent 2: Resource Discovery Agent (GPT-4o-mini)**
- Searches for 5-7 resources using Serper API
- Prioritizes open textbooks, PDFs, course notes
- Matches resources to book's table of contents
- Ensures legal, free, publicly accessible content

**Agent 3: Resource Validator (GPT-4o-mini)**
- Verifies URLs are functional (no 404s, paywalls)
- Checks NotebookLM compatibility (PDF, YouTube, web page)
- Validates licensing (Creative Commons, Open Access)
- Scores resources on usefulness (1-10)
- Filters out low-quality/illegal resources

**Agent 4: Output Formatter (GPT-4o)**
- Creates student-friendly markdown guide
- Organizes resources by topic/type
- Adds NotebookLM import instructions
- Includes study tips and workflow suggestions

### 4. Results Returned
- Frontend polls `/api/status/{job_id}` every 2 seconds
- When complete, displays results in table
- Student can copy URLs, share results link, or export to NotebookLM

---

## ğŸŒ API Endpoints

### `POST /api/submit`
Submit a new resource discovery job.

**Request Body:**
```json
{
  "university_name": "MIT",
  "course_name": "Introduction to Algorithms",
  "book_title": "Introduction to Algorithms",
  "book_author": "Cormen, Leiserson, Rivest, Stein",
  "isbn": "978-0262046305",
  "book_pdf_path": "",
  "book_url": "",
  "course_url": "",
  "textbook": "",
  "topics_list": ""
}
```

**Response:**
```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "pending",
  "message": "Job submitted successfully"
}
```

### `GET /api/status/{job_id}`
Get job status and results (for polling).

**Response (pending/running):**
```json
{
  "job_id": "550e8400-...",
  "status": "running",
  "status_message": "Analyzing book structure...",
  "search_title": "MIT Introduction to Algorithms",
  "created_at": "2025-12-20T10:30:00Z"
}
```

**Response (completed):**
```json
{
  "job_id": "550e8400-...",
  "status": "completed",
  "results": [
    {
      "type": "PDF",
      "title": "MIT 6.006 Course Notes",
      "source": "MIT OpenCourseWare",
      "url": "https://...",
      "description": "Comprehensive lecture notes..."
    }
  ],
  "raw_output": "# Study Resources for Introduction to Algorithms...",
  "created_at": "2025-12-20T10:30:00Z",
  "completed_at": "2025-12-20T10:33:45Z"
}
```

### `GET /api/results/{job_id}`
Get completed job results.

Returns 404 if job doesn't exist or isn't completed yet.

### `GET /api/health`
Health check endpoint.

**Response:**
```json
{
  "status": "healthy"
}
```

---

## ğŸš¢ Deployment

### Frontend Deployment (Cloudflare Pages)

1. **Connect GitHub repository** to Cloudflare Pages
2. **Build settings**:
   - Build command: `npm run build`
   - Build output directory: `web/dist`
   - Root directory: `web`
3. **Environment variables**:
   - `VITE_API_URL` = `https://your-backend.railway.app`

### Backend Deployment (Railway)

1. **Connect GitHub repository** to Railway
2. **Add environment variables**:
   - `OPENAI_API_KEY`
   - `SERPER_API_KEY`
   - `SUPABASE_URL`
   - `SUPABASE_KEY`
3. **Railway auto-detects** FastAPI and runs: `uvicorn backend.main:app --host 0.0.0.0 --port $PORT`
4. **Enable persistent storage** if saving files locally (optional)

### Database (Supabase)

Already set up during installation. No additional deployment needed.

**Scaling considerations:**
- Free tier: 500MB database, 50K MAU
- Upgrade to Pro ($25/mo) when hitting limits
- Consider adding indexes for frequently queried fields

---

## ğŸ“ Project Structure

```
/Users/teial/Tutorials/AI/scholar_source/
â”œâ”€â”€ backend/                      # FastAPI backend
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                   # API endpoints
â”‚   â”œâ”€â”€ models.py                 # Pydantic request/response models
â”‚   â”œâ”€â”€ database.py               # Supabase client
â”‚   â”œâ”€â”€ jobs.py                   # Background job management
â”‚   â”œâ”€â”€ crew_runner.py            # CrewAI integration wrapper
â”‚   â””â”€â”€ markdown_parser.py        # Parse crew output to JSON
â”‚
â”œâ”€â”€ web/                          # React/Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx               # Main app with routing
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ HomePage.jsx      # Main form page
â”‚   â”‚   â”‚   â””â”€â”€ ResultsPage.jsx   # Shareable results page
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ CourseForm.jsx    # Input form
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultsTable.jsx  # Results display
â”‚   â”‚   â”‚   â””â”€â”€ LoadingStatus.jsx # Job status polling
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ client.js         # API client functions
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”‚       â””â”€â”€ App.css           # Styles
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ src/scholar_source/           # CrewAI implementation
â”‚   â”œâ”€â”€ crew.py                   # Agent and task definitions
â”‚   â”œâ”€â”€ main.py                   # CLI entry point
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ agents.yaml           # Agent configurations
â”‚       â””â”€â”€ tasks.yaml            # Task descriptions
â”‚
â”œâ”€â”€ test_crew.py                  # Testing script
â”œâ”€â”€ pyproject.toml                # Python dependencies
â”œâ”€â”€ .env                          # Environment variables
â””â”€â”€ README.md                     # This file
```

---

## ğŸ” Understanding the Agents

ScholarSource uses a **sequential multi-agent workflow** powered by CrewAI:

### 1. Book Structure Analyst (`course_intelligence_agent`)
- **Role**: Extract table of contents and topics from student's book
- **Tools**: `FileReadTool` (reads PDFs)
- **Model**: GPT-4o (stronger reasoning for structure extraction)
- **Output**: Course title, topics list, key concepts, course level

### 2. Resource Discovery Agent (`resource_discovery_agent`)
- **Role**: Find 5-7 high-quality resources aligned with book structure
- **Tools**: `SerperDevTool` (web search)
- **Model**: GPT-4o-mini (cost-effective for search tasks)
- **Priority**: Open textbooks, PDFs, course notes (text-based for NotebookLM)
- **Output**: List of resources with URLs, descriptions, coverage topics

### 3. Resource Validator (`resource_validator_agent`)
- **Role**: Validate resource quality, legality, and NotebookLM compatibility
- **Tools**: `WebsiteSearchTool`, `YoutubeVideoSearchTool`
- **Model**: GPT-4o-mini (validation is straightforward)
- **Checks**: Accessibility, copyright, format compatibility, usefulness
- **Output**: Filtered list with validation scores (1-10)

### 4. Output Formatter (`output_formatter_agent`)
- **Role**: Create student-friendly markdown guide
- **Tools**: None (pure formatting)
- **Model**: GPT-4o (better at clear, structured writing)
- **Output**: Markdown document with resources organized by topic, import instructions, study tips

---

## ğŸ§ª Testing

### Test CrewAI Locally

```bash
# Run test script with verbose output
python test_crew.py

# Expected: 2-5 minute execution, generates report.md
```

### Test API Locally

```bash
# Terminal 1: Start backend
uvicorn backend.main:app --reload

# Terminal 2: Test endpoints
curl -X POST http://localhost:8000/api/submit \
  -H "Content-Type: application/json" \
  -d '{"book_title": "Introduction to Algorithms", "book_author": "Cormen"}'

# Copy job_id from response, then poll status
curl http://localhost:8000/api/status/{job_id}
```

### Test Frontend Locally

```bash
cd web
npm run dev

# Open http://localhost:5173
# Fill form and submit
# Watch status updates
# Verify results table displays correctly
```

---

## ğŸ› ï¸ Troubleshooting

### Startup Issues

**Problem**: Backend won't start
- **Check**: `.env` has `SUPABASE_URL` and `SUPABASE_KEY` configured
- **Check**: Virtual environment is activated (`source .venv/bin/activate`)
- **Check**: Dependencies installed correctly (`pip install -e .`)
- **Check**: Port 8000 isn't already in use

**Problem**: Frontend won't start
- **Check**: Dependencies installed (`cd web && npm install`)
- **Check**: Port 5173 isn't already in use
- **Check**: `VITE_API_URL` set in `web/.env.local`

### CrewAI Execution Issues

**Problem**: Agents can't find resources
- **Check**: `SERPER_API_KEY` is set in `.env`
- **Check**: SerperDevTool is working (test with `python test_crew.py`)
- **Note**: GPT-4o-mini sometimes struggles with SerperDevTool parameters. Consider upgrading resource_discovery_agent to GPT-4o if issues persist.

**Problem**: FileReadTool can't read PDF
- **Check**: PDF path is absolute, not relative
- **Check**: File exists and is readable
- **Check**: PDF is not encrypted or password-protected

### API Connection Issues

**Problem**: Frontend can't connect to backend
- **Check**: CORS is configured in `backend/main.py` for frontend origin (should include `http://localhost:5173`)
- **Check**: `VITE_API_URL` in `web/.env.local` matches backend URL (`http://localhost:8000`)
- **Check**: Backend is running on expected port (8000)

**Problem**: 404 on `/api/status/{job_id}`
- **Check**: Job ID is valid UUID
- **Check**: Job exists in Supabase `jobs` table
- **Check**: Database connection is working (check `SUPABASE_URL` and `SUPABASE_KEY`)

### Database Issues

**Problem**: Jobs not persisting
- **Check**: Supabase credentials in `.env`
- **Check**: `jobs` table exists (run SQL schema from [Installation](#-installation) section)
- **Check**: Row Level Security policies are set correctly
- **Check**: Supabase project is active (not paused)

---

## ğŸ“š Resources

- [CrewAI Documentation](https://docs.crewai.com)
- [FastAPI Documentation](https://fastapi.tiangolo.com)
- [React Documentation](https://react.dev)
- [Supabase Documentation](https://supabase.com/docs)
- [Railway Documentation](https://docs.railway.app)
- [Cloudflare Pages Documentation](https://developers.cloudflare.com/pages)

---

## ğŸ¤ Support

For questions or issues:
- Check the [troubleshooting section](#-troubleshooting) above
- Review the [CrewAI documentation](https://docs.crewai.com)
- [Join CrewAI Discord](https://discord.com/invite/X4JWnZnxPb)

---

## ğŸ“„ License

This project is built with CrewAI. See [CrewAI GitHub](https://github.com/joaomdmoura/crewai) for framework license details.
